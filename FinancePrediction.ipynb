{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nm4QiaOs9T3"
      },
      "outputs": [],
      "source": [
        "#Importing necessary libraries\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from textblob import Word\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the dataset\n",
        "data = pd.read_csv('data.csv')"
      ],
      "metadata": {
        "id": "k4N3ZIkatIZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_9I4BHAueHh",
        "outputId": "9276d41d-19bf-4cf5-e272-fb0487eb70d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Sentence', 'Sentiment'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Pre-Processing the text\n",
        "def cleaning(df, stop_words):\n",
        "    #df['sentences'] = df['Sentence'].apply(lambda x: ' '.join(x.lower() for x in x.split()))\n",
        "    df['Sentence'] = df['Sentence'].apply(lambda x: ' '.join([Word(word).lemmatize() for word in x.split()]))\n",
        "    # Replacing the digits/numbers\n",
        "    df['Sentence'] = df['Sentence'].str.replace('d', '')\n",
        "    # Removing stop words\n",
        "    df['Sentence'] = df['Sentence'].apply(lambda x: ' '.join(x for x in x.split() if x not in stop_words))\n",
        "    # Lemmatization\n",
        "    df['Sentence'] = df['Sentence'].apply(lambda x: ' '.join([Word(x).lemmatize() for x in x.split()]))\n",
        "    return df"
      ],
      "metadata": {
        "id": "X5VBasWttX2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04Twy2Mct0kx",
        "outputId": "b9c8ebf0-d68a-4fd0-be8a-a1bd540e697c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zJ933bOt63B",
        "outputId": "d18bc920-ce65-4e8b-8900-8ba4be65249c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')"
      ],
      "metadata": {
        "id": "0inMiKVIuBZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#stop_words = stopwords.words('english')\n",
        "data_cleaned = cleaning(data, stop_words)"
      ],
      "metadata": {
        "id": "2qN2d8HItldV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_cleaned.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnNXcrmqv17i",
        "outputId": "0df65855-b62b-4e3e-ad58-5db06e29f95f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Sentence', 'Sentiment'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generating Embeddings using tokenizer\n",
        "tokenizer = Tokenizer(num_words=500, split=' ')\n",
        "tokenizer.fit_on_texts(data_cleaned['Sentence'].values)\n",
        "#X = tokenizer.texts_to_sequences(data_cleaned['sentences'].values)\n",
        "#y = pad_sequences(X)\n",
        "reviews = data['Sentence'].values\n",
        "labels = data['Sentiment'].values\n",
        "encoder = LabelEncoder()\n",
        "encoded_labels = encoder.fit_transform(labels)"
      ],
      "metadata": {
        "id": "Uru57h86vuFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X\n",
        "#reviews\n",
        "encoded_labels\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9o0L-xZByEaS",
        "outputId": "1b938900-0aae-40c8-90c9-d8d5064f06df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 0, 2, ..., 1, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences, test_sentences, train_labels, test_labels = train_test_split(reviews, encoded_labels, stratify = encoded_labels)\n"
      ],
      "metadata": {
        "id": "3dAMgecYFUEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters of the model\n",
        "vocab_size = 3000 # choose based on statistics\n",
        "oov_tok = ''\n",
        "embedding_dim = 100\n",
        "max_length = 200 # choose based on statistics, for example 150 to 200\n",
        "padding_type='post'\n",
        "trunc_type='post'\n",
        "# tokenize sentences\n",
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(train_sentences)\n",
        "word_index = tokenizer.word_index\n",
        "# convert train dataset to sequence and pad sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
        "train_padded = pad_sequences(train_sequences, padding='post', maxlen=max_length)\n",
        "# convert Test dataset to sequence and pad sequences\n",
        "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
        "test_padded = pad_sequences(test_sequences, padding='post', maxlen=max_length)"
      ],
      "metadata": {
        "id": "nJAhb98bFhft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model initialization\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import keras\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    keras.layers.Bidirectional(keras.layers.LSTM(64)),\n",
        "    keras.layers.Dense(24, activation='relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "# compile model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "# model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQJfXJ_fFsQ0",
        "outputId": "ef6edb8c-8f61-4585-f367-7ab7bde3088d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 200, 100)          300000    \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 128)               84480     \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 24)                3096      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 25        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 387601 (1.48 MB)\n",
            "Trainable params: 387601 (1.48 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "history = model.fit(train_padded, train_labels,\n",
        "                    epochs=num_epochs, verbose=1,\n",
        "                    validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNl4g0xgGAZq",
        "outputId": "0a077847-4996-4256-e508-143f4fa1e871"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "124/124 [==============================] - 37s 262ms/step - loss: -4.9103 - accuracy: 0.5370 - val_loss: -17.5953 - val_accuracy: 0.5103\n",
            "Epoch 2/5\n",
            "124/124 [==============================] - 29s 238ms/step - loss: -21.7248 - accuracy: 0.5386 - val_loss: -47.4406 - val_accuracy: 0.5103\n",
            "Epoch 3/5\n",
            "124/124 [==============================] - 30s 241ms/step - loss: -47.3406 - accuracy: 0.5386 - val_loss: -92.5125 - val_accuracy: 0.5103\n",
            "Epoch 4/5\n",
            "124/124 [==============================] - 31s 247ms/step - loss: -84.0136 - accuracy: 0.5386 - val_loss: -151.8882 - val_accuracy: 0.5103\n",
            "Epoch 5/5\n",
            "124/124 [==============================] - 29s 237ms/step - loss: -131.1712 - accuracy: 0.5386 - val_loss: -227.1140 - val_accuracy: 0.5103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict(test_padded)\n",
        "# Get labels based on probability 1 if p>= 0.5 else 0\n",
        "pred_labels = []\n",
        "for i in prediction:\n",
        "    if i >= 0.5:\n",
        "        pred_labels.append(1)\n",
        "    else:\n",
        "        pred_labels.append(0)\n",
        "print(\"Accuracy of prediction on test set : \", accuracy_score(test_labels,pred_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q46jKcEHHEJl",
        "outputId": "8e9b6136-eab9-444a-c6c5-afa798e2f3f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46/46 [==============================] - 7s 115ms/step\n",
            "Accuracy of prediction on test set :  0.5359342915811088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KhFdug_OwUqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ds_split, info = tfds.load(\"penguins/processed\", split=['train[:20%]', 'train[20%:]'], as_supervised=True, with_info=True)\n",
        "\n",
        "#ds_test = ds_split[0]\n",
        "#ds_train = ds_split[1]\n",
        "#assert isinstance(ds_test, tf.data.Dataset)\n",
        "\n",
        "#print(info.features)\n",
        "#df_test = tfds.as_dataframe(ds_test.take(5), info)\n",
        "#print(\"Test dataset sample: \")\n",
        "#print(df_test)\n",
        "\n",
        "#df_train = tfds.as_dataframe(ds_train.take(5), info)\n",
        "#print(\"Train dataset sample: \")\n",
        "#print(df_train)\n",
        "\n",
        "#ds_train_batch = ds_train.batch(32)"
      ],
      "metadata": {
        "id": "CAPiXNvTzLsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W7l51-zwwdTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0hTtk1jZxKqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hINGdOuKxPGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hZ7eRromxpi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fWMhaiA-z9p-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lzKTbsSK0MSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dogR36vy0Rcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UeEOXOqR0Wi0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}